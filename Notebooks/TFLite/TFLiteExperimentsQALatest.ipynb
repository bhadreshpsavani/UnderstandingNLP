{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TFLiteExperimentsQALatest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c602ac1282874f00b8260ddaa75167f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a43d929c835d4109be410fbd3026e65b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_06233688bcea417e8c341fdea85f0db8",
              "IPY_MODEL_aad2f77fe18240dbae4bd4ce7ef5b463"
            ]
          }
        },
        "a43d929c835d4109be410fbd3026e65b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06233688bcea417e8c341fdea85f0db8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bd4ceb150cfd476aa17efee9023c5b1e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 451,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 451,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_24d120625eb14874b34c61c943df6821"
          }
        },
        "aad2f77fe18240dbae4bd4ce7ef5b463": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_82e048ca462545069654ac1b8e51e8a2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 451/451 [00:00&lt;00:00, 1.42kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_491ddf5f38ca45c0bb503fb2b04acf26"
          }
        },
        "bd4ceb150cfd476aa17efee9023c5b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "24d120625eb14874b34c61c943df6821": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "82e048ca462545069654ac1b8e51e8a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "491ddf5f38ca45c0bb503fb2b04acf26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2560890f05f14235943f703c2ada8446": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6d2cf6095dbb42738196788ab60202a3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8226a93187e64a029a36b817ec8e5c36",
              "IPY_MODEL_6490342044624bbf88af489a7a8fcaca"
            ]
          }
        },
        "6d2cf6095dbb42738196788ab60202a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8226a93187e64a029a36b817ec8e5c36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_738391f586114552b6e74761ad9733dd",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_021cda12afd9453bb1a0ff6b33aa9589"
          }
        },
        "6490342044624bbf88af489a7a8fcaca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3f313b7530db475c9ad3aba4733a4931",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 2.10MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a5bb4e29fc34c8e8d540d2e29d35561"
          }
        },
        "738391f586114552b6e74761ad9733dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "021cda12afd9453bb1a0ff6b33aa9589": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f313b7530db475c9ad3aba4733a4931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a5bb4e29fc34c8e8d540d2e29d35561": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb9a16060e424a45b74c3bb9ae97f516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1223cc564e6c4b7cb0ea0e3ab9cbd054",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6dc1e8de17694a69917666fb30b604ae",
              "IPY_MODEL_67736d85da7447109a496d6f90c22852"
            ]
          }
        },
        "1223cc564e6c4b7cb0ea0e3ab9cbd054": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6dc1e8de17694a69917666fb30b604ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_60245611737a435dbeba9f5cc224787d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 265582824,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 265582824,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_10e1ff870ebe416b895f895f441c8ca7"
          }
        },
        "67736d85da7447109a496d6f90c22852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a6e68e5ace0c4b6f8446b02b703107c6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 266M/266M [00:05&lt;00:00, 46.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3469443f10b54554adfee3903b8e5db8"
          }
        },
        "60245611737a435dbeba9f5cc224787d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "10e1ff870ebe416b895f895f441c8ca7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a6e68e5ace0c4b6f8446b02b703107c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3469443f10b54554adfee3903b8e5db8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a55b2e4157142f0a016e1b129dc7c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a846202ee2e438897dc8c03c0fade6d",
              "IPY_MODEL_b1dad2f770cc44e08f53584dd605bf52"
            ],
            "layout": "IPY_MODEL_f8b2958f90a444cd97a08661f20dcc29"
          }
        },
        "1a846202ee2e438897dc8c03c0fade6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_005729093953442d91563a11473c372c",
            "max": 890431403,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_293a19746b004f34a8d787063b48ebda",
            "value": 890431403
          }
        },
        "b1dad2f770cc44e08f53584dd605bf52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecfceda990ea4b448afa1bdd6c66abbc",
            "placeholder": "​",
            "style": "IPY_MODEL_66f6b4daa1bf43a69ce787dc2477b281",
            "value": " 890M/890M [00:33&lt;00:00, 26.9MB/s]"
          }
        },
        "f8b2958f90a444cd97a08661f20dcc29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "005729093953442d91563a11473c372c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "293a19746b004f34a8d787063b48ebda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "ecfceda990ea4b448afa1bdd6c66abbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66f6b4daa1bf43a69ce787dc2477b281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhadreshpsavani/UnderstandingNLP/blob/master/TFLiteExperimentsQALatest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8sEOhm13Y0U"
      },
      "source": [
        "## Import\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jauzLc3TsFz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78653d16-9cba-4aad-849c-dae841bba21a"
      },
      "source": [
        "!pip install -q tensorflow-gpu\n",
        "!pip install -q transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |██████████████████████████▎     | 263.4MB 1.3MB/s eta 0:00:45\u001b[31mERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/cli/base_command.py\", line 153, in _main\n",
            "    status = self.run(options, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py\", line 382, in run\n",
            "    resolver.resolve(requirement_set)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/legacy_resolve.py\", line 201, in resolve\n",
            "    self._resolve_one(requirement_set, req)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/legacy_resolve.py\", line 365, in _resolve_one\n",
            "    abstract_dist = self._get_abstract_dist_for(req_to_install)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/legacy_resolve.py\", line 313, in _get_abstract_dist_for\n",
            "    req, self.session, self.finder, self.require_hashes\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/operations/prepare.py\", line 194, in prepare_linked_requirement\n",
            "    progress_bar=self.progress_bar\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/download.py\", line 465, in unpack_url\n",
            "    progress_bar=progress_bar\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/download.py\", line 316, in unpack_http_url\n",
            "    progress_bar)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/download.py\", line 551, in _download_http_url\n",
            "    _download_url(resp, link, content_file, hashes, progress_bar)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/download.py\", line 253, in _download_url\n",
            "    hashes.check_against_chunks(downloaded_chunks)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/utils/hashes.py\", line 80, in check_against_chunks\n",
            "    for chunk in chunks:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/download.py\", line 223, in written_chunks\n",
            "    for chunk in chunks:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/utils/ui.py\", line 162, in iter\n",
            "    self.next(n)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/progress/__init__.py\", line 120, in next\n",
            "    self.update()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/progress/bar.py\", line 83, in update\n",
            "    self.writeln(line)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/progress/__init__.py\", line 101, in writeln\n",
            "    self.clearln()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/progress/__init__.py\", line 90, in clearln\n",
            "    print('\\r\\x1b[K', end='', file=self.file)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/utils/ui.py\", line 118, in handle_sigint\n",
            "    self.finish()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/utils/ui.py\", line 108, in finish\n",
            "    super(InterruptibleMixin, self).finish()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_vendor/progress/__init__.py\", line 107, in finish\n",
            "    print(file=self.file)\n",
            "RuntimeError: reentrant call inside <_io.BufferedWriter name='<stdout>'>\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 8.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 23.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 24.2MB/s \n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2Hz4F5jZ39Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce6f24a-5547-47ee-b934-ffc710f16bc5"
      },
      "source": [
        "import tensorflow as tf\n",
        "import warnings\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import json\n",
        "tqdm.pandas()\n",
        "warnings.filterwarnings('ignore')\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c7U3dSMzZxM"
      },
      "source": [
        "def json_to_dataframe(file):\n",
        "    f = open (file, \"r\") \n",
        "    data = json.loads(f.read())               #loading the json file.\n",
        "    iid = []                                  \n",
        "    tit = []                                  #Creating empty lists to store values.\n",
        "    con = []\n",
        "    Que = []\n",
        "    Ans_st = []\n",
        "    Txt = []\n",
        "    \n",
        "    for i in range(len(data['data'])):       #Root tag of the json file contains 'title' tag & 'paragraphs' list.\n",
        "        \n",
        "        title = data['data'][i]['title']\n",
        "        for p in range(len(data['data'][i]['paragraphs'])):  # 'paragraphs' list contains 'context' tag & 'qas' list.\n",
        "            \n",
        "            context = data['data'][i]['paragraphs'][p]['context']\n",
        "            for q in range(len(data['data'][i]['paragraphs'][p]['qas'])):  # 'qas' list contains 'question', 'Id' tag & 'answers' list.\n",
        "                \n",
        "                question = data['data'][i]['paragraphs'][p]['qas'][q]['question']\n",
        "                Id = data['data'][i]['paragraphs'][p]['qas'][q]['id']\n",
        "                for a in range(len(data['data'][i]['paragraphs'][p]['qas'][q]['answers'])): # 'answers' list contains 'ans_start', 'text' tags. \n",
        "                    \n",
        "                    ans_start = data['data'][i]['paragraphs'][p]['qas'][q]['answers'][a]['answer_start']\n",
        "                    text = data['data'][i]['paragraphs'][p]['qas'][q]['answers'][a]['text']\n",
        "                    \n",
        "                    tit.append(title)\n",
        "                    con.append(context)\n",
        "                    Que.append(question)                    # Appending values to lists\n",
        "                    iid.append(Id)\n",
        "                    Ans_st.append(ans_start)\n",
        "                    Txt.append(text)\n",
        "\n",
        "    print('Done')      # for indication perpose.\n",
        "    new_df = pd.DataFrame(columns=['Id','title','context','question','ans_start','text']) # Creating empty DataFrame.\n",
        "    new_df.Id = iid\n",
        "    new_df.title = tit           #intializing list values to the DataFrame.\n",
        "    new_df.context = con\n",
        "    new_df.question = Que\n",
        "    new_df.ans_start = Ans_st\n",
        "    new_df.text = Txt\n",
        "    print('Done')      # for indication perpose.\n",
        "    final_df = new_df.drop_duplicates(keep='first')  # Dropping duplicate rows from the create Dataframe.\n",
        "    return final_df\n",
        "\n",
        "def squad_json_to_dataframe_dev(input_file_path, record_path = ['data','paragraphs','qas','answers'],\n",
        "                           verbose = 1):\n",
        "    \"\"\"\n",
        "    input_file_path: path to the squad json file.\n",
        "    record_path: path to deepest level in json file default value is\n",
        "    ['data','paragraphs','qas','answers']\n",
        "    verbose: 0 to suppress it default is 1\n",
        "    \"\"\"\n",
        "    if verbose:\n",
        "        print(\"Reading the json file\")    \n",
        "    file = json.loads(open(input_file_path).read())\n",
        "    if verbose:\n",
        "        print(\"processing...\")\n",
        "    # parsing different level's in the json file\n",
        "    js = pd.io.json.json_normalize(file , record_path )\n",
        "    m = pd.io.json.json_normalize(file, record_path[:-1] )\n",
        "    r = pd.io.json.json_normalize(file,record_path[:-2])\n",
        "    \n",
        "    #combining it into single dataframe\n",
        "    idx = np.repeat(r['context'].values, r.qas.str.len())\n",
        "#     ndx  = np.repeat(m['id'].values,m['answers'].str.len())\n",
        "    m['context'] = idx\n",
        "#     js['q_idx'] = ndx\n",
        "    main = m[['id','question','context','answers']].set_index('id').reset_index()\n",
        "    main['c_id'] = main['context'].factorize()[0]\n",
        "    if verbose:\n",
        "        print(\"shape of the dataframe is {}\".format(main.shape))\n",
        "        print(\"Done\")\n",
        "    return main"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0tdTvgz1Wvo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "e3197e74-de54-48c0-98c8-7b4d0916e505"
      },
      "source": [
        "dev_df = squad_json_to_dataframe_dev('dev-v1.1.json')\n",
        "dev_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading the json file\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-359115a1a7ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdev_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msquad_json_to_dataframe_dev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dev-v1.1.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdev_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-9ad55484e7b1>\u001b[0m in \u001b[0;36msquad_json_to_dataframe_dev\u001b[0;34m(input_file_path, record_path, verbose)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reading the json file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"processing...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dev-v1.1.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdZltGoyrt40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "63ebc87b-12a8-42c8-869f-235ba3bdf3ae"
      },
      "source": [
        "dev_df['answers_len'] = dev_df['answers'].apply(lambda answers: len(answers))\n",
        "dev_df['answers_len'].hist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f74d9906828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6Jxf6Jcet5H"
      },
      "source": [
        "## Get Distilbert Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkVBsvu243wd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252,
          "referenced_widgets": [
            "c602ac1282874f00b8260ddaa75167f1",
            "a43d929c835d4109be410fbd3026e65b",
            "06233688bcea417e8c341fdea85f0db8",
            "aad2f77fe18240dbae4bd4ce7ef5b463",
            "bd4ceb150cfd476aa17efee9023c5b1e",
            "24d120625eb14874b34c61c943df6821",
            "82e048ca462545069654ac1b8e51e8a2",
            "491ddf5f38ca45c0bb503fb2b04acf26",
            "2560890f05f14235943f703c2ada8446",
            "6d2cf6095dbb42738196788ab60202a3",
            "8226a93187e64a029a36b817ec8e5c36",
            "6490342044624bbf88af489a7a8fcaca",
            "738391f586114552b6e74761ad9733dd",
            "021cda12afd9453bb1a0ff6b33aa9589",
            "3f313b7530db475c9ad3aba4733a4931",
            "7a5bb4e29fc34c8e8d540d2e29d35561",
            "fb9a16060e424a45b74c3bb9ae97f516",
            "1223cc564e6c4b7cb0ea0e3ab9cbd054",
            "6dc1e8de17694a69917666fb30b604ae",
            "67736d85da7447109a496d6f90c22852",
            "60245611737a435dbeba9f5cc224787d",
            "10e1ff870ebe416b895f895f441c8ca7",
            "a6e68e5ace0c4b6f8446b02b703107c6",
            "3469443f10b54554adfee3903b8e5db8"
          ]
        },
        "outputId": "fc8b3ea4-26d1-4e28-8beb-78938786b036"
      },
      "source": [
        "from transformers import  AutoTokenizer, TFAutoModelForQuestionAnswering\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased-distilled-squad')\n",
        "model =  TFAutoModelForQuestionAnswering.from_pretrained('distilbert-base-uncased-distilled-squad', return_dict=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c602ac1282874f00b8260ddaa75167f1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=451.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2560890f05f14235943f703c2ada8446",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb9a16060e424a45b74c3bb9ae97f516",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=265582824.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFDistilBertForQuestionAnswering.\n",
            "\n",
            "All the layers of TFDistilBertForQuestionAnswering were initialized from the model checkpoint at distilbert-base-uncased-distilled-squad.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForQuestionAnswering for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oSAJj6fZ39m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6790680a-0083-47d9-b2bb-754ce009c0e0"
      },
      "source": [
        "%%time\n",
        "question, text = \"Who was Jim Henson?\", \"Jim Henson was a nice puppet\"\n",
        "input_dict = tokenizer(question, text, padding='max_length', max_length=384,  truncation=True,  return_tensors='tf')\n",
        "outputs = model(input_dict)\n",
        "start_logits = outputs.start_logits\n",
        "end_logits = outputs.end_logits\n",
        "all_tokens = tokenizer.convert_ids_to_tokens(input_dict[\"input_ids\"].numpy()[0])\n",
        "answer =  tokenizer.convert_tokens_to_string(all_tokens[tf.math.argmax(start_logits, 1)[0] : tf.math.argmax(end_logits, 1)[0] +1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 58.1 ms, sys: 5.99 ms, total: 64.1 ms\n",
            "Wall time: 63.1 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3ptIU9R3S26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aaaf889-5568-4f14-f7bf-05810a33d7ca"
      },
      "source": [
        "input_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(1, 384), dtype=int32, numpy=\n",
              "array([[  101,  2040,  2001,  3958, 27227,  1029,   102,  3958, 27227,\n",
              "         2001,  1037,  3835, 13997,   102,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 384), dtype=int32, numpy=\n",
              "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRM4iXrlcv1h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "48995bee-e3da-473e-b387-f03c9f351979"
      },
      "source": [
        "answer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'a nice puppet'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKE4Cf9fZ39v"
      },
      "source": [
        "## Make Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6zSf_ygrt6Q"
      },
      "source": [
        "dev_df['answer_list'] = dev_df['answers'].apply(\n",
        "    lambda answers: [ans['text'] for ans in answers])\n",
        "\n",
        "dev_df['answer_mod'] =  dev_df['answer_list'].apply(\n",
        "    lambda answer_list: [(\n",
        "        tokenizer.decode(tokenizer(ans, add_special_tokens=False)['input_ids'],  \n",
        "                         skip_special_tokens=True)) for ans in answer_list])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLy-s4kDNgM6"
      },
      "source": [
        "def get_inputs(row):\n",
        "  ''' this func will tokenize question and context'''\n",
        "  return list(tokenizer(\n",
        "        row['question'], \n",
        "        row['context'], \n",
        "        padding='max_length', \n",
        "        max_length=384, \n",
        "        truncation=True,  \n",
        "        return_tensors='tf').values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1hZqVCjZ395",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1f83396-6c70-4b46-b818-62263f1ae672"
      },
      "source": [
        "dev_df['inputs']= dev_df.progress_apply(get_inputs, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10570/10570 [00:32<00:00, 329.96it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI1cUbPH4zze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7ae600b-964d-4876-9636-fd177b390017"
      },
      "source": [
        "dev_df['inputs'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(1, 384), dtype=int32, numpy=\n",
              " array([[  101,  2029,  5088,  2136,  3421,  1996, 10511,  2012,  3565,\n",
              "          4605,  2753,  1029,   102,  3565,  4605,  2753,  2001,  2019,\n",
              "          2137,  2374,  2208,  2000,  5646,  1996,  3410,  1997,  1996,\n",
              "          2120,  2374,  2223,  1006,  5088,  1007,  2005,  1996,  2325,\n",
              "          2161,  1012,  1996,  2137,  2374,  3034,  1006, 10511,  1007,\n",
              "          3410,  7573, 14169,  3249,  1996,  2120,  2374,  3034,  1006,\n",
              "         22309,  1007,  3410,  3792, 12915,  2484,  1516,  2184,  2000,\n",
              "          7796,  2037,  2353,  3565,  4605,  2516,  1012,  1996,  2208,\n",
              "          2001,  2209,  2006,  2337,  1021,  1010,  2355,  1010,  2012,\n",
              "         11902,  1005,  1055,  3346,  1999,  1996,  2624,  3799,  3016,\n",
              "          2181,  2012,  4203, 10254,  1010,  2662,  1012,  2004,  2023,\n",
              "          2001,  1996, 12951,  3565,  4605,  1010,  1996,  2223, 13155,\n",
              "          1996,  1000,  3585,  5315,  1000,  2007,  2536,  2751,  1011,\n",
              "         11773, 11107,  1010,  2004,  2092,  2004,  8184, 28324,  2075,\n",
              "          1996,  4535,  1997, 10324,  2169,  3565,  4605,  2208,  2007,\n",
              "          3142, 16371, 28990,  2015,  1006,  2104,  2029,  1996,  2208,\n",
              "          2052,  2031,  2042,  2124,  2004,  1000,  3565,  4605,  1048,\n",
              "          1000,  1007,  1010,  2061,  2008,  1996,  8154,  2071, 14500,\n",
              "          3444,  1996,  5640, 16371, 28990,  2015,  2753,  1012,   102,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(1, 384), dtype=int32, numpy=\n",
              " array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLDPHh-SZ399"
      },
      "source": [
        "def predict(inputs):\n",
        "  outputs = model(inputs)\n",
        "  start_ind=tf.math.argmax(outputs.start_logits, 1)[0] \n",
        "  end_ind=tf.math.argmax(outputs.end_logits, 1)[0] +1\n",
        "  answer = tokenizer.decode(inputs[0].numpy()[0][start_ind:end_ind], skip_special_tokens=True)\n",
        "  return answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt-8-cW3Z3-B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9405060a-2293-43d1-c909-2d81f00b0aa1"
      },
      "source": [
        "%%time\n",
        "dev_df['predictions'] = dev_df['inputs'].progress_apply(predict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10570/10570 [09:45<00:00, 18.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 9min 25s, sys: 20.5 s, total: 9min 46s\n",
            "Wall time: 9min 45s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkhX5uyyZ3-M"
      },
      "source": [
        "## Mesuring The BaseLine Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK2XeYS0Z3-M"
      },
      "source": [
        "\"\"\"Evaluation utilities.\"\"\"\n",
        "import argparse\n",
        "import collections\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "def normalize_answer(s):\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "    def remove_articles(text):\n",
        "        regex = re.compile(r'\\b(a|an|the)\\b', re.UNICODE)\n",
        "        return re.sub(regex, ' ', text)\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "\n",
        "def get_tokens(s):\n",
        "    if not s:\n",
        "        return []\n",
        "    return normalize_answer(s).split()\n",
        "\n",
        "\n",
        "def compute_exact(a_gold, a_pred):\n",
        "    return int(normalize_answer(a_gold) == normalize_answer(a_pred))\n",
        "\n",
        "\n",
        "def compute_f1(a_gold, a_pred):\n",
        "    gold_toks = get_tokens(a_gold)\n",
        "    pred_toks = get_tokens(a_pred)\n",
        "    common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n",
        "    num_same = sum(common.values())\n",
        "    if len(gold_toks) == 0 or len(pred_toks) == 0:\n",
        "        # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n",
        "        return int(gold_toks == pred_toks)\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    precision = 1.0 * num_same / len(pred_toks)\n",
        "    recall = 1.0 * num_same / len(gold_toks)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "def make_eval_dict(exact_scores, f1_scores):\n",
        "    total = len(exact_scores)\n",
        "    return collections.OrderedDict([(\"exact\", 100.0 * sum(exact_scores.values / total)), (\"f1\", 100.0 * sum(f1_scores.values / total)),(\"total\", total)])\n",
        "\n",
        "def find_f1(answers, prediction):\n",
        "    max_f1=0\n",
        "    for answer in answers:\n",
        "        f1 = compute_f1(answer, prediction)\n",
        "        max_f1 = max(max_f1, f1)\n",
        "    return max_f1\n",
        "\n",
        "def find_em(answers, prediction):\n",
        "    max_em=0\n",
        "    for answer in answers:\n",
        "        em = compute_exact(answer, prediction)\n",
        "        max_em = max(max_em, em)\n",
        "    return max_em"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFU0LW-ZZ3-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4c48a92-0580-4d15-86f2-93ac2e6a7ce9"
      },
      "source": [
        "dev_df['exact_match'] = dev_df.apply(lambda row:find_em(row['answer_mod'], row['predictions']), axis=1)\n",
        "dev_df['f1_score'] = dev_df.apply(lambda row:find_f1(row['answer_mod'], row['predictions']), axis=1)\n",
        "make_eval_dict(dev_df['exact_match'], dev_df['f1_score'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('exact', 77.71050141912077),\n",
              "             ('f1', 85.5370981182013),\n",
              "             ('total', 10570)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Il10shxPIU-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85fb809a-c596-4d70-eefb-f1a710ca21b8"
      },
      "source": [
        "(len(dev_df.query(\"predictions==''\"))/len(dev_df))*100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.1759697256385997"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIkFp5FFrt6k"
      },
      "source": [
        "faulty = dev_df.query(\"exact_match<1\").reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MhCVGUGrt6r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e43792b-ad48-4ce8-dec0-65f6ccebf517"
      },
      "source": [
        "for i in range(5):\n",
        "  print(\"Record: \", i, \", Id:\", faulty['id'][i])\n",
        "  print(\"Passage: \", faulty['context'][i])\n",
        "  print(\"Question: \", faulty['question'][i])\n",
        "  print(\"Targets: \", faulty['answers'].apply(lambda answers: ' [SEP] '.join([ans['text'] for ans in answers]))[i])\n",
        "  print(\"Predictions: \", faulty['predictions'][i], \"f1: \", faulty['f1_score'][i], \"em:\", faulty['exact_match'][i])\n",
        "  print(\"Normalize: \", faulty['predictions'][i])\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Record:  0 , Id: 56be4db0acb8001400a502ef\n",
            "Passage:  Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
            "Question:  Which NFL team won Super Bowl 50?\n",
            "Targets:  Denver Broncos [SEP] Denver Broncos [SEP] Denver Broncos\n",
            "Predictions:   f1:  0.0 em: 0\n",
            "Normalize:  \n",
            "\n",
            "Record:  1 , Id: 56be8e613aeaaa14008c90d1\n",
            "Passage:  Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
            "Question:  What was the theme of Super Bowl 50?\n",
            "Targets:  \"golden anniversary\" [SEP] gold-themed [SEP] \"golden anniversary\n",
            "Predictions:  arabic numerals f1:  0.0 em: 0\n",
            "Normalize:  arabic numerals\n",
            "\n",
            "Record:  2 , Id: 56bea9923aeaaa14008c91b9\n",
            "Passage:  Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
            "Question:  What was the theme of Super Bowl 50?\n",
            "Targets:  \"golden anniversary\" [SEP] gold-themed [SEP] gold\n",
            "Predictions:  arabic numerals f1:  0.0 em: 0\n",
            "Normalize:  arabic numerals\n",
            "\n",
            "Record:  3 , Id: 56d9895ddc89441400fdb50e\n",
            "Passage:  Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
            "Question:  The name of the NFL championship game is?\n",
            "Targets:  Super Bowl [SEP] Super Bowl [SEP] Super Bowl\n",
            "Predictions:  super bowl l f1:  0.8 em: 0\n",
            "Normalize:  super bowl l\n",
            "\n",
            "Record:  4 , Id: 56bead5a3aeaaa14008c91ea\n",
            "Passage:  The Panthers finished the regular season with a 15–1 record, and quarterback Cam Newton was named the NFL Most Valuable Player (MVP). They defeated the Arizona Cardinals 49–15 in the NFC Championship Game and advanced to their second Super Bowl appearance since the franchise was founded in 1995. The Broncos finished the regular season with a 12–4 record, and denied the New England Patriots a chance to defend their title from Super Bowl XLIX by defeating them 20–18 in the AFC Championship Game. They joined the Patriots, Dallas Cowboys, and Pittsburgh Steelers as one of four teams that have made eight appearances in the Super Bowl.\n",
            "Question:  Who lost to the Broncos in the AFC Championship?\n",
            "Targets:  New England Patriots [SEP] the New England Patriots [SEP] New England Patriots\n",
            "Predictions:  arizona cardinals f1:  0.0 em: 0\n",
            "Normalize:  arizona cardinals\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D2w4YQ4xzJE"
      },
      "source": [
        "### Results:\n",
        "* distilbert-base-uncased-distilled-squad: with 384 \n",
        "```\n",
        "OrderedDict([('exact', 77.71050141912077),\n",
        "             ('f1', 85.5370981182013),\n",
        "             ('total', 10570)])\n",
        "```\n",
        "\n",
        "* with 512 length:\n",
        "```\n",
        "OrderedDict([('exact', 77.93755912962224),\n",
        "             ('f1', 85.74265548166177),\n",
        "             ('total', 10570)])\n",
        "```\n",
        "\n",
        "**This model reaches a F1 score of 86.9**\n",
        "\n",
        "```\n",
        "Results: \n",
        "{ 'exact': 79.0728476821192, \n",
        "'f1': 86.85365868598011, \n",
        "'total': 10570, \n",
        "'HasAns_exact': 79.0728476821192, \n",
        "'HasAns_f1': 86.85365868598011, \n",
        "'HasAns_total': 10570, \n",
        "'best_exact': 79.0728476821192, \n",
        "'best_exact_thresh': 0.0, \n",
        "'best_f1': 86.85365868598011, \n",
        "'best_f1_thresh': 0.0}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp1TAzYQZ3-f"
      },
      "source": [
        "## Configure Model Input:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeLSlDJr_BCs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f655a827-e75e-4309-e7de-3e7d6462939d"
      },
      "source": [
        "input_spec = tf.TensorSpec([1, 384], tf.int32)\n",
        "# model._set_inputs(input_spec, training=False) # for tf < 2.2\n",
        "model._saved_model_inputs_spec = None # for tf > 2.2\n",
        "model._set_save_spec(input_spec) # for tf > 2.2\n",
        "input_spec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorSpec(shape=(1, 384), dtype=tf.int32, name=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj_ESLx7-ITF"
      },
      "source": [
        "model.save_weights('./tensorflow_distilbert/checkpoint')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd6BB7_sAvKG"
      },
      "source": [
        "# TensorFlow Lite:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7s4qb2WC6od7"
      },
      "source": [
        "## Post-training quantization:\n",
        "With Normal Converstion:\n",
        "[Article](https://www.tensorflow.org/lite/performance/post_training_quantization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jij_P2GhcZsc"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "# For normal conversion:\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNme-dKhclC6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff31fc8f-513c-491b-f350-05ed0d8ad4c6"
      },
      "source": [
        "tflite_model = converter.convert()\n",
        "open(\"distilbert.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0ac3e9a3c8>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0ac3d63d68>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0ac3e42390>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0ac3e4a978>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0ac3e51f60>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0ac3e615c0>, because it is not built.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpydzncqnl/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Using experimental converter: If you encountered a problem please file a bug. You can opt-out by setting experimental_new_converter=False\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "265276272"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUEGsdCQcB0d"
      },
      "source": [
        "# Load the TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=\"distilbert.tflite\")\n",
        "interpreter.allocate_tensors()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "801mpMuPccoL"
      },
      "source": [
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__ML6qEuaxg4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6405d6a5-1b28-4cc0-d5cb-85995524c30f"
      },
      "source": [
        "input_details"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'dtype': numpy.int32,\n",
              "  'index': 0,\n",
              "  'name': 'args_0',\n",
              "  'quantization': (0.0, 0),\n",
              "  'quantization_parameters': {'quantized_dimension': 0,\n",
              "   'scales': array([], dtype=float32),\n",
              "   'zero_points': array([], dtype=int32)},\n",
              "  'shape': array([  2, 384], dtype=int32),\n",
              "  'shape_signature': array([  2, 384], dtype=int32),\n",
              "  'sparsity_parameters': {}}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT0Rpyz7bYzc"
      },
      "source": [
        "combine_ = tf.concat([input_dict['input_ids'], input_dict['attention_mask']], 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycp5rB-EciZu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fe16ac1-ad09-4c70-a560-e74e16ecdf13"
      },
      "source": [
        "%%time\n",
        "interpreter.set_tensor(input_details[0]['index'], combine_)\n",
        "interpreter.invoke()\n",
        "end_logits  = interpreter.get_tensor(output_details[0]['index'])\n",
        "start_logits = interpreter.get_tensor(output_details[1]['index'])\n",
        "all_tokens = tokenizer.convert_ids_to_tokens(input_dict[\"input_ids\"].numpy()[0])\n",
        "answer = ' '.join(all_tokens[tf.math.argmax(start_logits, 1)[0] : tf.math.argmax(end_logits, 1)[0] +1])\n",
        "answer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.73 s, sys: 37.1 ms, total: 1.77 s\n",
            "Wall time: 947 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOD6BCikb2X3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6c0e0016-0817-4227-d06a-c6d0b31f8325"
      },
      "source": [
        "answer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'a nice puppet'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIEtJMV6Z3_A"
      },
      "source": [
        "def predict_tflite(input_ids):\n",
        "    interpreter.set_tensor(input_details[0]['index'], input_ids)\n",
        "    interpreter.invoke() # Run inference.\n",
        "    end_logits  = interpreter.get_tensor(output_details[0]['index'])\n",
        "    start_logits = interpreter.get_tensor(output_details[1]['index'])\n",
        "    all_tokens = tokenizer.convert_ids_to_tokens(input_ids.numpy()[0])\n",
        "    answer = ' '.join(all_tokens[tf.math.argmax(start_logits, 1)[0] : tf.math.argmax(end_logits, 1)[0] +1])\n",
        "    return answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a48orFfSZ3_C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3d0365c-ea42-4b79-b769-34aea745a3f8"
      },
      "source": [
        "%%time\n",
        "sample_df['tflite_answer'] = sample_df['input_ids'].progress_apply(predict_tflite)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10388/10388 [23:03<00:00,  7.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2h 46min 8s, sys: 14min 32s, total: 3h 40s\n",
            "Wall time: 23min 3s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuvHRsnSZ3_F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cea55804-4ea7-4f65-bbc8-6dc38be93b48"
      },
      "source": [
        "sample_df['exact_match'] = sample_df.apply(lambda row:compute_exact(row['target_text'], row['tflite_answer']), axis=1)\n",
        "sample_df['f1_score'] = sample_df.apply(lambda row:compute_f1(row['target_text'], row['tflite_answer']), axis=1)\n",
        "make_eval_dict(sample_df['exact_match'], sample_df['f1_score'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('exact', 28.47516365036527),\n",
              "             ('f1', 47.488564965527644),\n",
              "             ('total', 10388)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o99puRx8rt7o"
      },
      "source": [
        "```\n",
        "OrderedDict([('exact', 28.47516365036527),\n",
        "             ('f1', 47.488564965527644),\n",
        "             ('total', 10388)])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czFEpszS6wl6"
      },
      "source": [
        "## FP16 Quantization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHr49xzo6xRg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b15cf5c-7916-485d-f583-e881d8af9e91"
      },
      "source": [
        "# Below Two methods makes models size 4 time smaller\n",
        "# For conversion with FP16 quantization:\n",
        "# supports CPUs, GPUs\n",
        "converter_16 = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter_16.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "converter_16.target_spec.supported_types = [tf.float16]\n",
        "converter_16.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter_16.experimental_new_converter = True\n",
        "\n",
        "tflite_model_fp16 = converter_16.convert()\n",
        "open(\"distilbert_fp16.tflite\", \"wb\").write(tflite_model_fp16)\n",
        "\n",
        "# Load the TFLite model and allocate tensors.\n",
        "interpreter_fp16 = tf.lite.Interpreter(model_path=\"distilbert_fp16.tflite\")\n",
        "interpreter_fp16.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter_fp16.get_input_details()\n",
        "output_details = interpreter_fp16.get_output_details()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f3d3c0c9e50>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f3d3c0c9e50>, because it is not built.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f3d3c083640>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f3d3c083640>, because it is not built.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f3d3c089df0>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f3d3c089df0>, because it is not built.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f3d3c0945e0>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f3d3c0945e0>, because it is not built.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f3d3c09cd90>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f3d3c09cd90>, because it is not built.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f3d3c0a7580>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f3d3c0a7580>, because it is not built.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmph698ucx_/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmph698ucx_/assets\n",
            "INFO:absl:Using experimental converter: If you encountered a problem please file a bug. You can opt-out by setting experimental_new_converter=False\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzfUpaYBGEnv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ced4b00-a5e1-4ee6-fae3-4fbf3b1a17a5"
      },
      "source": [
        "%%time\n",
        "interpreter_fp16.set_tensor(input_details[0]['index'], input_dict['input_ids'])\n",
        "interpreter_fp16.invoke()\n",
        "output_data_fp16 = interpreter_fp16.get_tensor(output_details[0]['index'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.47 s, sys: 88.7 ms, total: 1.56 s\n",
            "Wall time: 1.54 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWEedTUsZ3_N"
      },
      "source": [
        "def predict_tflite_16(input_ids):\n",
        "    \n",
        "    interpreter_fp16.set_tensor(input_details[0]['index'], input_ids)\n",
        "    interpreter_fp16.invoke()\n",
        "    end_logits  = interpreter_fp16.get_tensor(output_details[0]['index'])\n",
        "    start_logits = interpreter_fp16.get_tensor(output_details[1]['index'])\n",
        "    \n",
        "    all_tokens = tokenizer.convert_ids_to_tokens(input_ids.numpy()[0])\n",
        "    answer = ' '.join(all_tokens[tf.math.argmax(start_logits, 1)[0] : tf.math.argmax(end_logits, 1)[0] +1])\n",
        "    return answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDCvej7YZ3_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56609cf3-8b46-4d5d-d0d2-eb7d0d5ec9f0"
      },
      "source": [
        "%%time\n",
        "sample_df['answer_text'] = sample_df['input_ids'].progress_apply(predict_tflite_16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  9%|▉         | 975/10388 [21:53<3:31:18,  1.35s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/media/data2/anaconda/envs/tflite-qa/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    768\u001b[0m                 \u001b[0;31m# on the df using our wrapper (which provides bar updating)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/media/data2/anaconda/envs/tflite-qa/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4198\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4200\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/media/data2/anaconda/envs/tflite-qa/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    763\u001b[0m                     \u001b[0;31m# take a fast or slow code path; so stop when t.total==t.n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-cdf43332b512>\u001b[0m in \u001b[0;36mpredict_tflite_16\u001b[0;34m(input_ids)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_tflite_16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minterpreter_fp16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_details\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0minterpreter_fp16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mend_logits\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0minterpreter_fp16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_details\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstart_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpreter_fp16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_details\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/media/data2/anaconda/envs/tflite-qa/lib/python3.8/site-packages/tensorflow/lite/python/interpreter.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \"\"\"\n\u001b[1;32m    523\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_all_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSr-itfoZ3_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aef2e11-368d-458e-833b-4e0ee14fa476"
      },
      "source": [
        "sample_df['exact_match'] = sample_df.apply(lambda row:compute_exact(row['target_text'], row['answer_text']), axis=1)\n",
        "sample_df['f1_score'] = sample_df.apply(lambda row:compute_f1(row['target_text'], row['answer_text']), axis=1)\n",
        "make_eval_dict(sample_df['exact_match'], sample_df['f1_score'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('exact', 46.000000000000036),\n",
              "             ('f1', 58.62087773284195),\n",
              "             ('total', 1000)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoDQn3Mjrt79"
      },
      "source": [
        "#### The advantages of float16 quantization are as follows:\n",
        "\n",
        "* It reduces model size by up to half (since all weights become half of their original size).\n",
        "* It causes minimal loss in accuracy.\n",
        "* It supports some delegates (e.g. the GPU delegate) which can operate directly on float16 data, resulting in faster execution than float32 computations.\n",
        "\n",
        "#### The disadvantages of float16 quantization are as follows:\n",
        "\n",
        "* It does not reduce latency as much as a quantization to fixed point math.\n",
        "* By default, a float16 quantized model will \"dequantize\" the weights values to float32 when run on the CPU. (Note that the GPU delegate will not perform this dequantization, since it can operate on float16 data.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hUa7H9Qrt7_"
      },
      "source": [
        "## Integer only: 16-bit activations with 8-bit weights:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieY8kl2frt7_",
        "outputId": "93947667-f8ec-415f-f4c4-12c0c371baec"
      },
      "source": [
        "# For conversion with hybrid quantization:\n",
        "# This only support CPU\n",
        "converter_int = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter_int.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "def representative_dataset_gen():\n",
        "    for _ in range(num_calibration_steps):\n",
        "    # Get sample input data as a numpy array in a method of your choosing.\n",
        "        yield [input]\n",
        "converter_int.representative_dataset = representative_dataset_gen\n",
        "converter_int.target_spec.supported_ops = [tf.lite.OpsSet.EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8,\n",
        "tf.lite.OpsSet.TFLITE_BUILTINS]\n",
        "\n",
        "converter_int = converter_int.convert()\n",
        "open(\"distilbert_int.tflite\", \"wb\").write(converter_int)\n",
        "\n",
        "# Load the TFLite model and allocate tensors.\n",
        "converter_int = tf.lite.Interpreter(model_path=\"distilbert_int.tflite\")\n",
        "converter_int.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = converter_int.get_input_details()\n",
        "output_details = converter_int.get_output_details()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f3d3c0c9e50>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f3d3c0c9e50>, because it is not built.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f3d3c083640>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f3d3c083640>, because it is not built.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f3d3c089df0>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f3d3c089df0>, because it is not built.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f3d3c0945e0>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f3d3c0945e0>, because it is not built.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f3d3c09cd90>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f3d3c09cd90>, because it is not built.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f3d3c0a7580>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f3d3c0a7580>, because it is not built.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp2yvuviwu/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp2yvuviwu/assets\n",
            "INFO:absl:Using experimental converter: If you encountered a problem please file a bug. You can opt-out by setting experimental_new_converter=False\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc46KrNtrt8C"
      },
      "source": [
        "```\n",
        "error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\n",
        "        tf.Erf {device = \"\"}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWzaG0gNrt8D"
      },
      "source": [
        "input_details"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rswxXmgrt8G"
      },
      "source": [
        "%%time\n",
        "converter_int.set_tensor(input_details[0]['index'], input_dict['input_ids'])\n",
        "converter_int.invoke()\n",
        "output_data_int = converter_int.get_tensor(output_details[0]['index'])\n",
        "output_data_int"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COuneARmrt8I"
      },
      "source": [
        "def predict_tflite_hy(input_ids):\n",
        "    interpreter_hy.set_tensor(input_details[0]['index'], input_ids)\n",
        "    interpreter_hy.invoke()\n",
        "    end_logits  = interpreter_hy.get_tensor(output_details[0]['index'])\n",
        "    start_logits = interpreter_hy.get_tensor(output_details[1]['index'])\n",
        "    all_tokens = tokenizer.convert_ids_to_tokens(input_ids.numpy()[0])\n",
        "    answer = ' '.join(all_tokens[tf.math.argmax(start_logits, 1)[0] : tf.math.argmax(end_logits, 1)[0] +1])\n",
        "    return answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t-G8R5v66-K"
      },
      "source": [
        "## Hybrid Quantization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T9Z0-Bl65QK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "951a82e8-958a-4c14-81db-73cf21f6782f"
      },
      "source": [
        "# For conversion with hybrid quantization:\n",
        "# This only support CPU\n",
        "converter_hy = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter_hy.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "converter_hy.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "converter_hy.experimental_new_converter = True\n",
        "\n",
        "tflite_model_hy = converter_hy.convert()\n",
        "open(\"distilbert_hy.tflite\", \"wb\").write(tflite_model_hy)\n",
        "\n",
        "# Load the TFLite model and allocate tensors.\n",
        "interpreter_hy = tf.lite.Interpreter(model_path=\"distilbert_hy.tflite\")\n",
        "interpreter_hy.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter_hy.get_input_details()\n",
        "output_details = interpreter_hy.get_output_details()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f96702a21f0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f966db5a9a0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f966db62f70>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f966db6d940>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f966db74f10>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f966db7f8e0>, because it is not built.\n",
            "WARNING:tensorflow:From /media/data2/anaconda/envs/tflite-qa/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /media/data2/anaconda/envs/tflite-qa/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpnmy2_s_w/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Using experimental converter: If you encountered a problem please file a bug. You can opt-out by setting experimental_new_converter=False\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM1zWvqFGNIH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3789ce8e-6195-4fe9-b402-c4fb48372c18"
      },
      "source": [
        "%%time\n",
        "interpreter_hy.set_tensor(input_details[0]['index'], input_dict['input_ids'])\n",
        "interpreter_hy.invoke()\n",
        "output_data_hy = interpreter_hy.get_tensor(output_details[0]['index'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.95 s, sys: 7.32 ms, total: 1.96 s\n",
            "Wall time: 1.93 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.6909831 , -4.9051    , -6.399869  , -8.390377  , -6.6977587 ,\n",
              "        -6.7278447 , -0.35113093, -5.3920016 , -2.0406876 , -4.384707  ,\n",
              "        -2.5614827 ,  1.4131409 ,  5.979256  , -0.37855712, -3.793209  ,\n",
              "        -3.8040218 , -3.9716723 , -4.5060306 , -4.75165   , -4.9802365 ,\n",
              "        -4.931692  , -4.899516  , -4.7135115 , -4.777755  , -4.3580575 ,\n",
              "        -4.444338  , -4.3133726 , -3.9932828 , -3.9930396 , -4.1759768 ,\n",
              "        -4.4542947 , -4.374062  , -4.243202  , -4.3907394 , -4.534927  ,\n",
              "        -4.3255086 , -4.6032224 , -4.4600224 , -4.2206135 , -4.3227386 ,\n",
              "        -4.401688  , -4.3720765 , -4.3045764 , -4.3306403 , -4.517559  ,\n",
              "        -4.5653744 , -4.385817  , -4.386184  , -4.3745694 , -4.3306427 ,\n",
              "        -4.442092  , -4.546895  , -4.475903  , -4.6722817 , -4.8291416 ,\n",
              "        -4.807096  , -4.672144  , -4.720174  , -4.8751225 , -4.8795094 ,\n",
              "        -4.9085393 , -4.7816024 , -4.4566436 , -4.3426867 , -4.410192  ,\n",
              "        -4.0127954 , -3.9783676 , -4.0740733 , -4.1378202 , -4.4473567 ,\n",
              "        -4.597683  , -4.769646  , -5.1507444 , -5.310088  , -5.5721507 ,\n",
              "        -6.0510216 , -5.931256  , -6.1828437 , -6.4410415 , -6.009036  ,\n",
              "        -6.1432076 , -6.07324   , -6.2162247 , -6.0282006 , -5.8426867 ,\n",
              "        -5.757289  , -5.840088  , -5.8138576 , -6.1089153 , -6.396444  ,\n",
              "        -6.337208  , -6.1838636 , -6.247258  , -6.1260905 , -6.067652  ,\n",
              "        -6.1305227 , -6.01898   , -6.1810045 , -6.444432  , -6.6702895 ,\n",
              "        -6.8137712 , -6.9935837 , -7.371482  , -7.6137547 , -7.760553  ,\n",
              "        -7.666859  , -7.649195  , -7.302731  , -7.2811484 , -7.1954837 ,\n",
              "        -7.2510214 , -7.3245006 , -7.2391267 , -7.2275634 , -7.5429435 ,\n",
              "        -7.671201  , -7.6919518 , -7.909414  , -7.963955  , -7.8593373 ,\n",
              "        -7.7774377 , -7.6224146 , -7.7437778 , -7.937646  , -8.212055  ,\n",
              "        -8.245185  , -8.46538   , -8.537385  , -8.608765  , -8.8107395 ,\n",
              "        -8.860604  , -8.984927  , -9.116447  , -9.083147  , -9.104878  ,\n",
              "        -9.117946  , -9.009788  , -8.943874  , -8.905866  , -8.942439  ,\n",
              "        -8.866705  , -8.855339  , -8.83654   , -8.847246  , -8.746154  ,\n",
              "        -8.811137  , -8.901072  , -8.901397  , -9.002275  , -8.977166  ,\n",
              "        -9.000856  , -8.857992  , -9.036556  , -8.865601  , -8.647653  ,\n",
              "        -8.603913  , -8.519386  , -8.540807  , -8.441666  , -8.628182  ,\n",
              "        -8.636698  , -8.616597  , -8.604856  , -8.567849  , -8.737878  ,\n",
              "        -8.579983  , -8.636734  , -8.700717  , -8.456546  , -8.53047   ,\n",
              "        -8.522062  , -8.572136  , -8.581406  , -8.539203  , -8.479022  ,\n",
              "        -8.511141  , -8.460228  , -8.45668   , -8.467536  , -8.590272  ,\n",
              "        -8.6169815 , -8.516203  , -8.567456  , -8.595559  , -8.607094  ,\n",
              "        -8.648224  , -8.532424  , -8.419576  , -8.240737  , -8.34605   ,\n",
              "        -8.34971   , -8.337166  , -8.264875  , -8.293905  , -8.187104  ,\n",
              "        -8.300166  , -8.302239  , -8.37692   , -8.4102335 , -8.3941765 ,\n",
              "        -8.3730345 , -8.400747  , -8.386391  , -8.475022  , -8.499523  ,\n",
              "        -8.613261  , -8.496264  , -8.431014  , -8.383832  , -8.440517  ,\n",
              "        -8.44054   , -8.423095  , -8.381121  , -8.477085  , -8.522636  ,\n",
              "        -8.606533  , -8.570062  , -8.575529  , -8.44936   , -8.395923  ,\n",
              "        -8.498373  , -8.279979  , -8.164128  , -8.287075  , -8.145628  ,\n",
              "        -8.119816  , -8.100091  , -8.330186  , -8.279617  , -8.426602  ,\n",
              "        -8.373374  , -8.404052  , -8.380583  , -8.363979  , -8.38603   ,\n",
              "        -8.348077  , -8.384115  , -8.327925  , -8.211907  , -8.229191  ,\n",
              "        -8.200446  , -8.22224   , -8.1850195 , -8.285412  , -8.463065  ,\n",
              "        -8.528627  , -8.5482235 , -8.64298   , -8.602584  , -8.69458   ,\n",
              "        -8.599475  , -8.593643  , -8.5856695 , -8.554614  , -8.611631  ,\n",
              "        -8.381056  , -8.557237  , -8.592569  , -8.634407  , -8.702135  ,\n",
              "        -8.851799  , -8.783471  , -8.942608  , -8.730087  , -8.621955  ,\n",
              "        -8.556441  , -8.543497  , -8.631524  , -8.4202385 , -8.38007   ,\n",
              "        -8.362585  , -8.370884  , -8.5610695 , -8.436309  , -8.594338  ,\n",
              "        -8.644397  , -8.631045  , -8.735774  , -8.68488   , -8.655659  ,\n",
              "        -8.626388  , -8.657826  , -8.647135  , -8.716577  , -8.614684  ,\n",
              "        -8.634638  , -8.761608  , -8.646056  , -8.491505  , -8.541942  ,\n",
              "        -8.528722  , -8.490244  , -8.353362  , -8.574874  , -8.555789  ,\n",
              "        -8.588705  , -8.794234  , -8.720993  , -8.727951  , -8.47713   ,\n",
              "        -8.647416  , -8.691161  , -8.517529  , -8.523007  , -8.444603  ,\n",
              "        -8.603127  , -8.619048  , -8.607875  , -8.638552  , -8.808501  ,\n",
              "        -8.799508  , -8.58063   , -8.736433  , -8.709155  , -8.825142  ,\n",
              "        -8.958519  , -8.818332  , -8.911115  , -8.915245  , -8.887332  ,\n",
              "        -8.723046  , -8.790605  , -8.71904   , -8.775806  , -8.773064  ,\n",
              "        -8.724375  , -8.813218  , -8.796909  , -8.762968  , -8.908758  ,\n",
              "        -8.799221  , -8.752909  , -8.788058  , -8.920073  , -8.712426  ,\n",
              "        -8.766397  , -8.82659   , -8.645182  , -8.702621  , -8.6505    ,\n",
              "        -8.74219   , -8.75836   , -8.75248   , -8.845285  , -8.797039  ,\n",
              "        -8.810345  , -8.695372  , -8.786169  , -8.764715  , -8.767252  ,\n",
              "        -8.944923  , -8.852459  , -8.792655  , -8.71183   , -8.781327  ,\n",
              "        -8.614278  , -8.736058  , -8.605977  , -8.587823  , -8.433254  ,\n",
              "        -8.35163   , -8.284857  , -8.255246  , -8.16887   , -8.190308  ,\n",
              "        -8.263438  , -8.400828  , -8.372223  , -8.617601  , -8.707138  ,\n",
              "        -8.592488  , -8.633242  , -8.388931  , -8.770537  , -8.645168  ,\n",
              "        -8.747422  , -8.859978  , -8.624547  , -8.623301  , -8.597787  ,\n",
              "        -8.525242  , -8.610879  , -8.726521  , -8.7784    , -8.738149  ,\n",
              "        -8.862039  , -8.901802  , -8.875185  , -8.929682  , -8.940283  ,\n",
              "        -8.962717  , -8.974073  , -8.912207  , -9.040621  , -9.038766  ,\n",
              "        -8.9943495 , -9.0437    , -8.959877  , -8.95653   , -8.944535  ,\n",
              "        -8.932299  , -8.948047  , -8.998141  , -8.701098  , -8.814749  ,\n",
              "        -8.757284  , -8.78477   , -8.882528  , -8.895764  , -8.888251  ,\n",
              "        -8.9651985 , -8.982637  , -8.942835  , -9.093027  , -9.185485  ,\n",
              "        -9.089742  , -8.983942  , -8.985234  , -9.052203  , -8.90136   ,\n",
              "        -8.902439  , -8.978038  , -8.851617  , -8.988516  , -8.981655  ,\n",
              "        -9.064275  , -9.052678  , -8.987585  , -8.75355   , -8.807172  ,\n",
              "        -8.726132  , -8.859537  , -8.813332  , -8.833406  , -8.757033  ,\n",
              "        -8.854564  , -8.770628  , -8.982271  , -8.86533   , -8.816189  ,\n",
              "        -8.767917  , -8.689245  , -8.870028  , -8.87079   , -8.836359  ,\n",
              "        -8.978531  , -8.948923  , -8.937765  , -8.850884  , -8.822566  ,\n",
              "        -8.781947  , -8.7303505 , -8.778456  , -8.827415  , -8.827369  ,\n",
              "        -8.91171   , -8.928912  , -8.875857  , -8.810475  , -8.822227  ,\n",
              "        -8.888721  , -8.976016  , -8.803837  , -8.774887  , -8.849715  ,\n",
              "        -8.797579  , -8.821505  , -8.754639  , -8.573469  , -8.624228  ,\n",
              "        -8.587236  , -8.6112    , -8.5633545 , -8.5024395 , -8.703942  ,\n",
              "        -8.704118  , -8.655684  , -8.580333  , -8.619822  , -8.575051  ,\n",
              "        -8.682461  , -8.643128  , -8.670781  , -8.601146  , -8.523261  ,\n",
              "        -8.578685  , -8.578085  , -8.614027  , -8.63339   , -8.5889015 ,\n",
              "        -8.523222  , -8.551577  , -8.698884  , -8.629906  , -8.568451  ,\n",
              "        -8.588469  , -8.725127  , -8.570103  , -8.510605  , -8.479602  ,\n",
              "        -8.368765  , -8.375871  , -8.469633  , -8.313301  , -8.382138  ,\n",
              "        -8.220304  , -8.331938  , -8.387008  , -8.358178  , -8.458579  ,\n",
              "        -8.644016  , -8.656803  ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQP2udIlZ3_b"
      },
      "source": [
        "def predict_tflite_hy(input_ids):\n",
        "    interpreter_hy.set_tensor(input_details[0]['index'], input_ids)\n",
        "    interpreter_hy.invoke()\n",
        "    end_logits  = interpreter_hy.get_tensor(output_details[0]['index'])\n",
        "    start_logits = interpreter_hy.get_tensor(output_details[1]['index'])\n",
        "    all_tokens = tokenizer.convert_ids_to_tokens(input_ids.numpy()[0])\n",
        "    answer = ' '.join(all_tokens[tf.math.argmax(start_logits, 1)[0] : tf.math.argmax(end_logits, 1)[0] +1])\n",
        "    return answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP-KIAiKZ3_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7fee314-dbe8-4a3e-8783-bfbba52e79af"
      },
      "source": [
        "%%time\n",
        "sample_df['answer_text'] = sample_df['input_ids'].apply(predict_tflite_hy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 32min 12s, sys: 1.55 s, total: 32min 14s\n",
            "Wall time: 32min 7s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQTAMlcgZ3_g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81e9feb9-5b67-4266-c482-e4735b446bf9"
      },
      "source": [
        "sample_df['exact_match'] = sample_df.apply(lambda row:compute_exact(row['target_text'], row['answer_text']), axis=1)\n",
        "sample_df['f1_score'] = sample_df.apply(lambda row:compute_f1(row['target_text'], row['answer_text']), axis=1)\n",
        "make_eval_dict(sample_df['exact_match'], sample_df['f1_score'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('exact', 45.10000000000004),\n",
              "             ('f1', 57.11463039269687),\n",
              "             ('total', 1000)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZRh4hDV802v"
      },
      "source": [
        "## Observations:\n",
        "For DistilBert For Sequence Classification Model here is Our Observation\n",
        "\n",
        "|Method|Model Weight Size| Single Observation |Inference Time| F1_Score | Exact Match |\n",
        "|----- | ----| ----- | ---- | ---- | --- |\n",
        "| Normal Tensorflow Model | 253.85 Mb | 1.18s | 3h 23min 44s | 48.88 | 28.47 |\n",
        "| Normal TFLite | 253.33 Mb| 1.06s | 3h 40s  | 48.88 | 28.47 |\n",
        "| TFLite with FP16 Quantization | 126.88 Mb | 1.56s |  4h 30min| 48.88 | 28.47 |\n",
        "| TFLite With Hybrid Quantization | 64.87 Mb | 1.94s | 5h 39min | | |\n",
        "\n",
        "* Support Fix Length Inputs\n",
        "* Only Support TensorFLow and Keras Model\n",
        "* TFlite might not support Complex Model input While Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP50Ax3Oydeg"
      },
      "source": [
        "## Albert:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayTyaTmtNGoX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "5a55b2e4157142f0a016e1b129dc7c9e",
            "1a846202ee2e438897dc8c03c0fade6d",
            "b1dad2f770cc44e08f53584dd605bf52",
            "f8b2958f90a444cd97a08661f20dcc29",
            "005729093953442d91563a11473c372c",
            "293a19746b004f34a8d787063b48ebda",
            "ecfceda990ea4b448afa1bdd6c66abbc",
            "66f6b4daa1bf43a69ce787dc2477b281"
          ]
        },
        "outputId": "01a5de9d-da9f-494e-be5b-d940a054ddc2"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ahotrod/albert_xxlargev1_squad2_512\")\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"ahotrod/albert_xxlargev1_squad2_512\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a55b2e4157142f0a016e1b129dc7c9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=890431403.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txp8izMcOU9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b7a9291-71f0-4dfe-97a0-6014c61fed94"
      },
      "source": [
        "question, text = \"Who was Jim Henson?\", \"Jim Henson was a nice puppet\"\n",
        "input_dict = tokenizer(question, text, padding='max_length', max_length=512,  truncation=True,  return_tensors='tf')\n",
        "input_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n",
              "array([[    2,    72,    23,  2170, 27674,    60,     3,  2170, 27674,\n",
              "           23,    21,  2210, 10956,     3,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0]],\n",
              "      dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n",
              "array([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n",
              "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0]], dtype=int32)>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWWn_N_SPYf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "cb30e8f3-036f-4454-8014-9d15f31744ac"
      },
      "source": [
        "outputs = model(input_dict['input_ids'])\n",
        "start_logits = outputs.start_logits\n",
        "end_logits = outputs.end_logits\n",
        "all_tokens = tokenizer.convert_ids_to_tokens(input_dict[\"input_ids\"].numpy()[0])\n",
        "answer = ' '.join(all_tokens[tf.math.argmax(start_logits, 1)[0] : tf.math.argmax(end_logits, 1)[0]+1])\n",
        "answer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-2c6e6ff34b5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstart_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mend_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mall_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_ids_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1183\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m         )\n\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You cannot specify both input_ids and inputs_embeds at the same time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'size'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_LTR2Bu0XC-"
      },
      "source": [
        "## Roberta:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIkOfncF0lXV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "5c1ba9c0-a42e-4de2-87de-2f6b57859866"
      },
      "source": [
        "from transformers import RobertaTokenizer, TFRobertaForSequenceClassification\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = TFRobertaForSequenceClassification.from_pretrained('roberta-base', return_dict=True)\n",
        "\n",
        "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"tf\")\n",
        "inputs[\"labels\"] = tf.reshape(tf.constant(1), (-1, 1)) # Batch size 1\n",
        "\n",
        "outputs = model(inputs)\n",
        "loss = outputs.loss\n",
        "logits = outputs.logits"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaForSequenceClassification: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkBxZ100Z4AD",
        "outputId": "08732040-818b-42ef-bcca-35fbb2905d51"
      },
      "source": [
        "input_spec = tf.TensorSpec([1, 8], tf.int32)\n",
        "model._set_inputs(input_spec, training=False) # for tf < 2.2\n",
        "# model._saved_model_inputs_spec = None # for tf > 2.2\n",
        "# model._set_save_spec(input_spec) # for tf > 2.2\n",
        "input_spec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorSpec(shape=(1, 8), dtype=tf.int32, name=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiSYlHVr2alV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "96da3d81-cfb4-4365-c784-61eb1110fe58"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# For normal conversion:\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "open(\"roberta.tflite\", \"wb\").write(tflite_model)\n",
        "\n",
        "# Load the TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=\"roberta.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmphxx9i1ig/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmphxx9i1ig/assets\n",
            "INFO:absl:Using experimental converter: If you encountered a problem please file a bug. You can opt-out by setting experimental_new_converter=False\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtShZz3q2e0P"
      },
      "source": [
        "%%time\n",
        "interpreter.set_tensor(input_details[0]['index'], inputs['input_ids'])\n",
        "interpreter.invoke()\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(output_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UN42Zronrt80"
      },
      "source": [
        "## Observations:\n",
        "* Models, which consist primarily of convolutional layers, get 10–50% faster execution\n",
        "* RNN-based models get up to 3x speed-up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RrwUkGC5Kib"
      },
      "source": [
        "Reference:\n",
        "* https://discuss.huggingface.co/t/how-can-we-test-transformer-models-after-converting-it-to-tflite-format/1670/4\n",
        "* https://www.tensorflow.org/lite/guide/inference\n",
        "* https://github.com/huggingface/tflite-android-transformers/blob/master/models_generation/distilbert.py\n",
        "* https://www.tensorflow.org/lite/performance/post_training_quantization\n",
        "* https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_lite/tflite_c02_transfer_learning.ipynb\n",
        "* https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_lite/tflite_c04_exercise_convert_model_to_tflite_solution.ipynb\n",
        "* https://blog.tensorflow.org/2018/09/introducing-model-optimization-toolkit.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74im3jIRyb4F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}